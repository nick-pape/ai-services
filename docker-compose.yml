version: "3.9"

services:
  kokoro-fastapi:
    container_name: kokoro-fastapi
    image: dustynv/kokoro-tts:fastapi-r36.4.0-cu128-24.04
    restart: always
    platform: linux/arm64/v8
    runtime: nvidia
    gpus: all
    environment:
      NVIDIA_REQUIRE_CUDA: "cuda>=12.6"
      CUDA_VERSION: "12.6.0"
      NVIDIA_VISIBLE_DEVICES: "all"
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ports:
      - "8880:8880"

  ollama:
    container_name: ollama
    image: ollama/ollama:latest
    restart: always
    platform: linux/arm64/v8
    runtime: nvidia
    gpus: all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      NVIDIA_VISIBLE_DEVICES: "all"
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
    volumes:
      - ./ollama:/root/.ollama
    ports:
      - "11434:11434"
    stdin_open: true
    tty: true

  open-webui:
    container_name: open-webui
    image: ghcr.io/open-webui/open-webui:main
    restart: always
    platform: linux/arm64/v8
    runtime: nvidia
    gpus: all
    network_mode: host
    environment:
      TTS_BACKEND_URL: http://127.0.0.1:8880
      OLLAMA_BASE_URL: http://127.0.0.1:11434
    volumes:
      - ${HOME}/open-webui:/app/backend/data
    depends_on:
      - ollama

